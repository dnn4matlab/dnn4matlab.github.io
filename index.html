<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="dnn4matlab.github.io : " />
    <link rel="shortcut icon" href="http://dnn4matlab.github.io/images/favicon.ico" >
    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Deep Neural Networks for Matlab</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/dnn4matlab/code">View on GitHub</a>

          <h1 id="project_title">Deep Neural Networks for Matlab</h1>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h3>
<a name="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages"><span class="octicon octicon-link"></span></a>Overview</h3>

<p>dnn4matlab provides a fast CPU and GPU (CUDA) code to train large neural networks. Code is developed in Matlab, and contains CUDA bindings. With this code
we deliver trained models on ImageNet dataset, which gives top-5 accuracy 13% on ImageNet validation set. Main focus of this code is to give reasonable computer vision models
to people having no experience in field. If you look for broader (harder) framework then we recommend to use <a href="http://www.torch.ch" target="_blank">Torch 7</a>. Feel free to use, modify and sell dnn4matlab for any purpose (commercial, or academic). Please just mention at the end where you get it from.</p>

<p> To get started just checkout our repository:</p>
<pre><code>$ git clone https://github.com/dnn4matlab/code
</code></pre>

Code runs as it is without any compilation on CPU. However, to enable GPU support you have to compile CUDA libraries. Our code supports
only NVIDIA GPUs, and we recommend to use at least GTX 480. To compile code go to the directory <a href="https://github.com/dnn4matlab/code/blob/master/gpu" target="_blank">/gpu</a>
and call <code>make</code>.


<h3><a name="designer-templates" class="anchor" href="#designer-templates"><span class="octicon octicon-link"></span></a>Evaluate ImageNet trained model on your data</h3>

<p>File <a href="https://github.com/dnn4matlab/code/blob/master/eval.m" target="_blank">/eval.m</a> shows how to evaluate trained model on your data. It first downloads
trained model from a server, and stores it into <a href="https://github.com/dnn4matlab/code/blob/master/models" target="_blank">/models</a> directory (this is done only once). 

<pre><code>load_imagenet_model();
predictions = test("data/doggy.png");% You can use an url.
fprinf('Top-5 predictions:\n');
predictions(1:5)
</code></pre>

Evaluating a single image is quite slow in compare to evaluating many images in the same time. We recommend to store 128 images of the size 224 x 224 in a single array. 
Code <a href="https://github.com/dnn4matlab/code/blob/master/eval128.m" target="_blank">/eval128.m</a> shows how to evaluate 128 images simultaneously. This might take a second
at first, because we download entire imagenet validation set (50k images) from our servers.</p>
<pre><code>load_imagenet_model();
imgs = get_images()
predictions = test(imgs);
for i = 1, 128
  imagesc(squeeze(imgs(i, :, :, :)))
  predictions(i, 1)
  waitforbuttonpress
end
</code></pre>
<p>This code displays best prediction for every out of 128 examples.</p>


<h3><a name="rather-drive-stick" class="anchor" href="#rather-drive-stick"><span class="octicon octicon-link"></span></a>Train your own model</h3>
<p>Files in a directory <a href="https://github.com/dnn4matlab/code/blob/master/plans/" target="_blank">/plans</a> describe various neural networks architecture. 
Feel free to define your own architectures, and try how they work. We provide reasonable architectures for MNIST, CIFAR-10, and ImageNet models.</p>

Models available in this package achieve following performance (you can find current state-of-art at <a href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html" target="_blank">here</a>):
</br>
</br>
<center>
<table style="text-align: center;">
  <tr>
    <th>Dataset</th>
    <th>Top-1 error</th> 
    <th>Top-5 error</th> 
  </tr>
  <tr>
    <td>MNIST</td>
    <td></td> 
    <td>no one cares</td> 
  </tr>
  <tr>
    <td>CIFAR-10</td>
    <td></td> 
    <td>no one cares</td> 
  </tr>
  <tr>
    <td>ImageNet</td>
    <td></td> 
    <td></td> 
  </tr>
</table>
</center>

<p>File <a href="https://github.com/dnn4matlab/code/blob/master/training.m" target="_blank">/training.m</a> trains MNIST model. It first downloads MNIST dataset.</p>
<pre><code>addpath(genpath('.'));
% Choose any out of following three plans.
% Plan('cifar');
% Plan('imagenet');
Plan('mnist');
Run();</code></pre>

<p>Models are stored in directory <a href="https://github.com/dnn4matlab/code/blob/master/models" target="_blank">/models</a>. Call 
<code>Plan('mnist');</code>
loads most recently trained model. To start from scratch just remove trained model file models/mnist.mat.</p>


<p>If you want to train a cifar model uncomment line <code>Plan('cifar');</code>. To train ImageNet model you have to download training data from 
<a href="http://www.image-net.org/" target="_blank">Image-Net website</a>.
Please place entire training dataset in <a href="https://github.com/dnn4matlab/code/blob/master/data/imagenet" target="_blank">/data/imagenet</a> directory. Then uncomment line
<code>Plan('imagenet');</code>, and start training.
Training takes around 6 days on NVIDIA Titan GPU. You need at least GTX 480 to train this model. Training on a CPU would take ages.</p>

<h3><a name="rather-drive-stick" class="anchor" href="#rather-drive-stick"><span class="octicon octicon-link"></span></a>Internals</h3>
<p>Entire model is a global variable called <b>Plan</b>. To access it call <code>global plan</code>.
All layers are stored in a directory <a href="https://github.com/dnn4matlab/code/blob/master/layers" target="_blank">/layers</a>, and code to verify their correctness is a file <a href="https://github.com/dnn4matlab/code/blob/master/tests/GC.m" target="_blank">/tests/GC.m (gradient checker)</a>. To test new layer, please extend file <a href="https://github.com/dnn4matlab/code/blob/master/plans/tests.txt" target="_blank">/plans/tests.m</a>, and run <a href="https://github.com/dnn4matlab/code/blob/master/tests/GC.m" target="_blank">/tests/GC.m</a>. Moreover, to check that your GPU code is equivalent to your CPU code call <a href="https://github.com/dnn4matlab/code/blob/master/tests/GC_gpu.m" target="_blank">/tests/GC_gpu.m</a>.</p> 


<h3><a name="authors-and-contributors" class="anchor" href="#authors-and-contributors"><span class="octicon octicon-link"></span></a>Authors</h3>

<p>Project developed by Emily Denton, <a href="http://www.cs.nyu.edu/~zaremba/" target="_blank">Wojciech Zaremba</a>, <a href="http://cims.nyu.edu/~bruna/" target="_blank">Joan Bruna</a>, and <a href="http://cs.nyu.edu/~fergus/" target="_blank">Rob Fergus</a>. If you use this package, please cite:</p>
<pre><code>@article{denton2014exploiting,
 title={Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation},
 author={Denton, Emily and Zaremba, Wojciech and Bruna, Joan and LeCun, Yann and Fergus, Rob},
 journal={arXiv preprint arXiv:1404.0736},
 year={2014}
}
</code></pre>
<p>Have fun!</p>

<h3>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
